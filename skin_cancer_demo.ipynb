{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Load Model and Pre-Processing Steps\n","\n","* Label encoder\n","* Tabular transformer\n","* ResNet50 image featuriser\n","* Image PCA\n","* Fitted model of choice"],"metadata":{"id":"78-V4WcH15fW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0L-1UXRIR1B"},"outputs":[],"source":["import pickle\n","\n","# Load label encoder\n","with open(\"skin_cancer_encode_labels.preprocess\", \"rb\") as file:\n","    label_encoder = pickle.load(file)\n","# Load tabular preprocessor\n","with open(\"skin_cancer_tabular.preprocess\", \"rb\") as file:\n","    tabular_preprocessor = pickle.load(file)\n","# Load PCA for CNN\n","with open(\"skin_cancer_image_pca.preprocess\", \"rb\") as file:\n","    image_pca = pickle.load(file)\n","# Load model\n","with open(\"ovr_en_logreg.model\", \"rb\") as file:\n","    model = pickle.load(file)"]},{"cell_type":"code","source":["try:\n","    import tensorflow as tf\n","except:\n","    !pip install tensorflow\n","    import tensorflow as tf\n","\n","# Load pre-trained CNN\n","pre_cnn_model = tf.keras.applications.ResNet50(\n","    include_top=False,  # Remove classification head\n","    input_shape=(85, 85, 3),  # Input shape that the model is most used to\n","    pooling='avg',      # Return vector\n","    weights='imagenet'  # Pre-trained weights\n",")\n","pre_cnn_model.trainable = False\n","\n","# Check\n","# pre_cnn_model.summary()\n","\n","def featurise_image(image):\n","    # Build complete CNN based on dimensions of input image\n","    # Not the most elegant but ensures most reproducibility compared to original pre-processing\n","    # Input layer is shape of NumPy array\n","    inputs = tf.keras.Input(shape=image.shape)\n","    # Crop into square - minimum of height, weight\n","    sq_size = min(image.shape[0], image.shape[1])\n","    cropped = tf.keras.layers.CenterCrop(sq_size, sq_size)(inputs)\n","    # Resize down\n","    resized = tf.keras.layers.Resizing(85, 85)(cropped)\n","    # Reorder RGB to BGR and normalise\n","    scaled = tf.keras.applications.resnet.preprocess_input(resized)\n","    # Get features using CNN model\n","    output_features = pre_cnn_model(scaled)\n","    # Compile models with these layers\n","    image_featuriser = tf.keras.Model(inputs, output_features)\n","    image_featuriser.trainable = False\n","\n","    # CNN model expects batches, so add extra dimension of size 1\n","    image_np = np.expand_dims(image, axis=0)\n","    # Featurise and return\n","    return image_featuriser(image_np, training=False).numpy()"],"metadata":{"id":"x7qUGTfyisk8","executionInfo":{"status":"ok","timestamp":1765203859966,"user_tz":360,"elapsed":17192,"user":{"displayName":"Vishnumaya Nair","userId":"00077965269941169457"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"72477b18-d30d-48df-8c18-2920a32018e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"]}]},{"cell_type":"markdown","source":["# Demo\n","\n","* Define function to generate predictions\n","* Use Gradio to wrap UI around that function"],"metadata":{"id":"xfvceyBw2Evn"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Define function to get prediction from inputs\n","def predict_dx(image, age, sex, localization):\n","    # Process tabular data\n","    tabular_df = pd.DataFrame([[age,sex,localization]], columns=[\"age\",\"sex\",\"localization\"])\n","    # Transform\n","    tabular_np = tabular_preprocessor.transform(tabular_df)\n","\n","    # Get features from image\n","    image_features_np = featurise_image(image)\n","    # Apply PCA\n","    image_features_np = image_pca.transform(image_features_np)\n","\n","    # Concatenate features together\n","    all_features_np = np.concatenate((image_features_np, tabular_np), axis=1)\n","\n","    # Get prediction\n","    prediction = model.predict(all_features_np)\n","    # If prediction is 2-D array, it means returned probabilities for classes so apply argmax\n","    if prediction.ndim > 1:\n","        prediction = np.argmax(prediction, axis=1)\n","    # Now have label, inverse transform with label encoder to get label name\n","    return label_encoder.inverse_transform(prediction)[0]"],"metadata":{"id":"KIQv2IYw7xGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","\n","# Close previous Gradio things to be sure\n","gr.close_all()\n","\n","# Get sex categories as one-hot encoder knows them\n","sex_values = tabular_preprocessor.named_transformers_['cat'].categories_[0]\n","# Same with localisation\n","local_values = tabular_preprocessor.named_transformers_['cat'].categories_[1]\n","\n","demo = gr.Interface(\n","    fn=predict_dx,\n","    inputs=[gr.Image(),\n","            gr.Slider(minimum=0, maximum=85, step=1),\n","            gr.Radio(sex_values.tolist()),\n","            gr.Radio(local_values.tolist())\n","            ],\n","    outputs=[\"text\"],\n",")\n","\n","demo.launch()"],"metadata":{"id":"PSwmgJCVKFx9","colab":{"base_uri":"https://localhost:8080/","height":663},"outputId":"ee057e20-54d8-418a-ff56-dbee31fd55b2","executionInfo":{"status":"ok","timestamp":1765205608785,"user_tz":360,"elapsed":3777,"user":{"displayName":"Vishnumaya Nair","userId":"00077965269941169457"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Closing server running on port: 7860\n","It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://6e61f8ba8444bf0151.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://6e61f8ba8444bf0151.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]}]}